bene, ora abbiamo analizzato ed esplicitato tutti i probelmi derivanti dalla suddivisione (split) di valori continui come quelli delle score PCA in calssi discrete. Abbiamo capito che il class method non influenza molto il conservation costs. quindi scelgo quantile perché è intuitivo, scelgo 6 classi perché è veloce, scelgo priorizr perché permette di raggiungere targets anche per le classi.

Qualisono gli altri algoritmi per piazzare demand points con raptr? Fare delle prove con Diplodus, multivariato con vario numero di assi, con gli algoritmi hypervolume implementati in raptr.

Ho scoperto che all'aumentare del numero di asse PCA inseriti, diminuisce il maximum target. Bisogna quindi definire bene il maximum target in introduzione. Bisognerebbe anche vedere come questo risultato cambia con i parametri dell'hypervolume. In particolare, mi dice che sto usando pochi punti random, e che le dimensioni sono eccessive. Inoltre, perché ho casì tanti punti che hanno gli stessi valori su tutte le PCA? interpolazione non funziona? Una volta risolti questi problemi, posso mettere a sistema anche il metodo hypervolume con gli altri. Quindi oggi.

1) Proviamo a scrivere la sezione sui fattori che inlfuenzano gli algoritmi SCP e la sezione metodi in cui descriviamo effettivamente gli scenari testati.
 -- OK, ho scritto quella sui fattori e quella sui metodi, e anche alcuni pezzi che andranno in discussione. Resta da vedere bene cosa abbiamo trovato nei risultati e collegare ai metodi.

2) Guardiamo bene perché ci sono così tanti doppioni nei valori delle scores genetiche interpolate. Potrebbe succedere se i valori da interpolare sono essi stessi uguali. Meglio se riusciamo a guardarlo su QGis. Anche su Mullus succede così? 
 -- Sembra che sia a causa dell'inverse distance weighting. per ora lasciamo così, ma menzioniamo in discussione tra gli altri fattori che possono causare variazioni, anche il tipo di interpolazione spaziale.

3) Recuperiamo il risultato su maximum target nell'hypervolume e irrobustiamolo usano parametraggi più intensivi. Rimane comunque il risultato che, per parametraggi computazionalmente fattibili, il risultato c'è.
 -- Ho provato sia ad aumentare il numero dei demand points, sia ad aumentare il numero dei sampling points, e i risultati non cambiano di molto. Ora provo a spingere ancora di più i parametri:
1) mi limito a nPCA = 5 massimo, così da avere log number of observation maggiore
2) aumento abbestia il numero di sampling points
samples.per.point=5000, n=500L: non supera i 0.978 per 4 PCA.

Ho capito cosa fa. Distribuisce valori random all'interno di un hypervolume. ma siccome i punti possono essere disgiunti, allora la distribuzione va a campionare anche regioni non abitate. Quindi meglio mettere un dp per valore unico e pesarlo per quante PUs. Riesce, ma ci fermiamo qui e andiamo avanti col paper.


Or vorrei:

1) riallacciare i risultati passati con quanto scritto nei metodi
2) mettere questi nuovi risultati su hypervolume in relazione con i risultati vecchi e con i metodi. 
insomma i metodi dovrebbero permettere di arrivare a tutti e due.

Mi sono accorto che voglio fare delle repliche intra scenario. le facci poi confronto con altri scenari

26/08/2023
Ho fatto repliche intra scenario. Con prioritizr, ho 13 scenari (10 con PCA singole; 3 con PCA composte in clusters). Confronto gli scenari con tre sistemi
1) calcolo distanza di Jaccard tra frequenza di selezione delle PU (su 100 repliche): risultano distanze alte (0.9). Le testo con test di permutazione, sono tutte significative (per prioritizr)(sia su Diplodus, sia su Mullus)
2) valuto se le soluzioni di uno scenario raggiungono i target di altri scenari. In generale no: per alcuni scenari (esempio quelli di equal interval) le soluzioni dell'uno soddisfano anche gli altri; ma in generale no. Molte features hanno shortfall di rappresentazione, cioè quante PU mancano in termini relativi per raggiungere il target proporzionale del 15%. Tra gli scenari a PCA singola, comunque, lo shortfall di rappresentazione è sempre molto piccolo, intorno al 2%. Invece le soluzioni degli scenari che combinano le PCA generano shortfall molto più grandi (10%-15%) quando sono valutate in relazione ai target degli scenari a PCA singola. (per prioritizr)(solo su Mullus, e shortfall solo per problems[[1]])
3) valuto il costo di conservazione
